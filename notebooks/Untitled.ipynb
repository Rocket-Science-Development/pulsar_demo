{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb11436-f7de-4d50-8c94-1877521b1605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mytoken pulsarml demo\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from influxdb_client import InfluxDBClient\n",
    "from pulsar_data_collection.database_connectors.influxdb import Influxdb\n",
    "import os\n",
    "\n",
    "# Set up InfluxDB connection\n",
    "# token = os.getenv(\"DOCKER_INFLUXDB_INIT_ADMIN_TOKEN\")\n",
    "# org = os.getenv(\"DOCKER_INFLUXDB_INIT_ORG\")\n",
    "# bucket_name = os.getenv(\"DOCKER_INFLUXDB_INIT_BUCKET\")\n",
    "token = 'mytoken'\n",
    "org = 'pulsarml'\n",
    "bucket_name = 'demo'\n",
    "url = 'http://influxdb:8086'\n",
    "\n",
    "print(token, org, bucket_name)\n",
    "# Create an instance of Influxdb from your package\n",
    "influxdb = Influxdb().get_database_actions()\n",
    "\n",
    "db_login = {\n",
    "    \"url\": url,\n",
    "    \"token\": token,\n",
    "    \"org\": org,\n",
    "    \"bucket_name\": bucket_name\n",
    "}\n",
    "\n",
    "# Test InfluxDB connection\n",
    "db_connection = influxdb.make_connection(**db_login)\n",
    "if db_connection:\n",
    "    print(\"Connection successful\")\n",
    "else:\n",
    "    print(\"Connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d36ed7-d65e-49b9-bd22-2a391f9aefc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tasks\n",
      "_monitoring\n",
      "demo\n"
     ]
    }
   ],
   "source": [
    "# Print the existing bucket names\n",
    "client = InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "buckets_api = client.buckets_api()\n",
    "buckets = buckets_api.find_buckets()\n",
    "\n",
    "for bucket in buckets.buckets:\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca366b9-cdfb-4a15-aea9-40cf75f207df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from gen_data_and_simulate_drift import DriftIntensity, DriftSimulator, GenerateFakeData\n",
    "from training_script import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cafc208-eb41-4913-b73b-f3e0e403373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legendary\n"
     ]
    }
   ],
   "source": [
    "pokemon_test_data='pokemon.csv'\n",
    "SAMPLE_SIZE=1000\n",
    "target = 'Legendary'\n",
    "genertor_fake_data = GenerateFakeData(path_ref_data=pokemon_test_data, sample_size=SAMPLE_SIZE, target=target)\n",
    "sampled_data = genertor_fake_data.get_dataclass_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a017fd26-803e-4b60-bccb-2d7f533a574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1320925\ttotal: 97.7ms\tremaining: 97.7ms\n",
      "1:\tlearn: 0.0470756\ttotal: 104ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# if the task is classification\n",
    "pok_classifier = Classifier(df_train=sampled_data.train_data,\n",
    "            num_features=sampled_data.list_num_col,\n",
    "            cat_features=None,\n",
    "            target=target,\n",
    "            pkl_file_path=f'class_{target}_model.pkl')\n",
    "pok_classifier.train()\n",
    "pok_classifier.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1260bc-10b7-4258-953e-d35c1feb28dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns to drift is : 1\n",
      "select random column to drift ...\n",
      "Drifting column Sp. Atk\n",
      "info: #                      int64\n",
      "Total                  int64\n",
      "HP                     int64\n",
      "Attack                 int64\n",
      "Defense                int64\n",
      "Sp. Atk                int64\n",
      "Sp. Def                int64\n",
      "Speed                  int64\n",
      "Generation             int64\n",
      "Legendary               bool\n",
      "timestamp     datetime64[ns]\n",
      "dtype: object\n",
      "drift data:        #  Total   HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  Generation  \\\n",
      "588  292    554   56      82      159      246       97     90           2   \n",
      "249  775    687  137     164       90      146       64    110           6   \n",
      "874  491    689   86     138       60      158      105     95           3   \n",
      "621  537    504   82     129       82      160       52     46           5   \n",
      "581   46    522  101      60       76      222      105     74           1   \n",
      "..   ...    ...  ...     ...      ...      ...      ...    ...         ...   \n",
      "55   402    422   66      48       72      217       56    113           4   \n",
      "623  613    358   80      53       61      172       92     31           5   \n",
      "497  618    227   31      11        6      274       40     88           5   \n",
      "360   94    242   47      30       58       65       41     41           0   \n",
      "806  610    361   63      47       74       98       91     25           4   \n",
      "\n",
      "     Legendary                  timestamp  \n",
      "588       True 2023-06-08 04:20:59.900792  \n",
      "249       True 2023-06-08 04:20:59.900792  \n",
      "874       True 2023-06-08 04:20:59.900792  \n",
      "621      False 2023-06-08 04:20:59.900792  \n",
      "581      False 2023-06-08 04:20:59.900792  \n",
      "..         ...                        ...  \n",
      "55       False 2023-06-08 04:20:59.900792  \n",
      "623      False 2023-06-08 04:20:59.900792  \n",
      "497      False 2023-06-08 04:20:59.900792  \n",
      "360      False 2023-06-08 04:20:59.900792  \n",
      "806      False 2023-06-08 04:20:59.900792  \n",
      "\n",
      "[400 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from datetime import datetime\n",
    "drift_sim_info = DriftSimulator(sampled_data, nb_cols_to_drift=1, drift_intensity=DriftIntensity.MODERATE)\n",
    "# to get test_data after drifting\n",
    "   \n",
    "df_test_drifted = drift_sim_info.get_test_data_drifted()\n",
    "df_test_drifted[\"timestamp\"] = datetime.now()\n",
    "print('info:',df_test_drifted.dtypes)\n",
    "print('drift data:',df_test_drifted)\n",
    "# df_test_drifted[target] = df_test_drifted[target].astype(int)\n",
    "\n",
    "prediction = pok_classifier.predict(df_test=df_test_drifted)\n",
    "prediction_int = [1 if e=='True' else 0 for e in prediction]\n",
    "prediction_numpy = numpy.asarray(prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fd0702-e0aa-4a3d-8dde-be9caad33bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_dictionary: {'client': <influxdb_client.client.influxdb_client.InfluxDBClient object at 0x4055e209d0>, 'bucket_name': 'demo', 'data_frame_measurement_name': 'mod1_ver1_input_data', 'data_frame_timestamp_column': 'timestamp', 'tags': {'model_id': 'mod1', 'model_version': 'ver1', 'data_id': 'data1'}}\n",
      "api_client: <influxdb_client._sync.api_client.ApiClient object at 0x404b873f40>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "param_dict = influxdb.create_param_dict(\n",
    "    client=db_connection,\n",
    "    login=db_login,\n",
    "    bucket_name=bucket_name,\n",
    "    model_id=\"mod1\",\n",
    "    model_version=\"ver1\",\n",
    "    data_id=\"data1\",\n",
    "    timestamp_column_name=\"timestamp\",\n",
    "    timestamp=datetime.now(),\n",
    "    additional_tags={}\n",
    "    )\n",
    "\n",
    "print('param_dictionary:',param_dict)\n",
    "\n",
    "print('api_client:',client.api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b10f4a40-8d2e-4fa3-8345-379ae9de6a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataWithPrediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorage Engine for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataWithPrediction\u001b[39;00m(BaseModel):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Model of input for capture_data method of Pulse parameter class\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConfig\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[8], line 121\u001b[0m, in \u001b[0;36mDataWithPrediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_tags \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39madditional_tags\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_engine\u001b[38;5;241m.\u001b[39mcreate_param_dict(client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb_connection, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata\u001b[38;5;241m.\u001b[39mdict())\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapture_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[43mDataWithPrediction\u001b[49m):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Capturing data from inference code\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    127\u001b[0m         {\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_points\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\u001b[38;5;241m.\u001b[39mdata_points,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m         }\n\u001b[1;32m    132\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataWithPrediction' is not defined"
     ]
    }
   ],
   "source": [
    "import pulsar_data_collection.database_connectors.influxdb as influxdb\n",
    "factories = {\"influxdb\": influxdb.Influxdb()}\n",
    "\n",
    "import datetime\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, validator\n",
    "\n",
    "\n",
    "class PulseParameters(BaseModel):\n",
    "    \"\"\"\n",
    "    Model of input Pulse class\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model_id: str\n",
    "    Model identifier\n",
    "    model_version: str\n",
    "    Model version\n",
    "    data_id: str\n",
    "    Data identifier\n",
    "    reference_data_storage: Any  # Union[str, Dict[str, str]]\n",
    "    Storage path for reference data used in drift recognition, usually training dataset\n",
    "    target_name: str\n",
    "    Name of target feature\n",
    "    storage_engine: str\n",
    "    Storage engine used to store collected logs\n",
    "    login: Dict[str, Union[str, int, bool]]\n",
    "    Dictionary containing the element required to perform successful login to storage engine\n",
    "    features_metadata: Optional[Dict[str, type]]  # key: feature_name, value : feature type\n",
    "    Dictionary containing the schema of features used for the model prediction\n",
    "    other_labels: Optional[Dict[str, Union[str, int, bool]]] = None\n",
    "    Dictionary of additional labels used provide more metadata regarding the context surrounding the model\n",
    "    timestamp_column_name: str = \"timestamp\"\n",
    "    Name of the column containing the timestamp\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_id: str\n",
    "    model_version: str\n",
    "    data_id: str\n",
    "    reference_data_storage: Any  # Union[str, Dict[str, str]]\n",
    "    target_name: str\n",
    "    storage_engine: str\n",
    "    login: Dict[str, Union[str, int, bool]]\n",
    "    features_metadata: Optional[Dict[str, type]]  # key: feature_name, value : feature type\n",
    "    additional_tags: Optional[Dict[str, Union[str, int, bool]]] = None\n",
    "    timestamp_column_name: str = \"timestamp\"\n",
    "\n",
    "    @validator(\"storage_engine\")\n",
    "    def check_storage_engine(cls, value):\n",
    "        if value not in factories:\n",
    "            raise ValueError(f\"Storage Engine for {value} not supported\")\n",
    "        return value\n",
    "\n",
    "\n",
    "class DataWithPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Model of input for capture_data method of Pulse parameter class\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    prediction_id: Optional[str]\n",
    "    Identifier of prediction\n",
    "    timestamp: datetime.datetime = datetime.datetime.now()\n",
    "    timestamp of when the prediction have been performed\n",
    "    predictions: Any  # Union[Dict, pd.DataFrame]\n",
    "    Object containing the array of predictions\n",
    "    data_points: pd.DataFrame\n",
    "    Object containing the data points on which the predicitions were performed\n",
    "    features_names: List[str]\n",
    "    list of features that were used to perform the prediction\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    prediction_id: Optional[str]\n",
    "    timestamp: datetime.datetime\n",
    "    predictions: Any\n",
    "    data_points: pd.DataFrame\n",
    "    features_names: List[str]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class Pulse:\n",
    "    \"\"\"\n",
    "    This class expose methods in order to collect data from\n",
    "    an inference container/webapp\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: PulseParameters):\n",
    "        \"\"\"\n",
    "        Initializing Pulse class instance\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data : PulseParameters\n",
    "        Pydantic Model providing the interface to the class constructor,\n",
    "        Refer to PulseParameters model attributes for detailed list of inputs\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.model_id = data.model_id\n",
    "        self.model_version = data.model_version\n",
    "        self.reference_data_storage = data.reference_data_storage\n",
    "        self.target_name = data.target_name\n",
    "        factory = factories.get(data.storage_engine)\n",
    "        self.storage_engine = factory.get_database_actions()\n",
    "        self.db_connection = self.storage_engine.make_connection(**data.login)\n",
    "        self.additional_tags = data.additional_tags\n",
    "        self.params = self.storage_engine.create_param_dict(client=self.db_connection, **data.dict())\n",
    "\n",
    "    def capture_data(self, data: DataWithPrediction):\n",
    "        \"\"\"\n",
    "        Capturing data from inference code\n",
    "        \"\"\"\n",
    "\n",
    "        self.params.update(\n",
    "            {\n",
    "                \"data_points\": data.data_points,\n",
    "                \"prediction\": data.predictions,\n",
    "                \"timestamp\": data.timestamp,\n",
    "            }\n",
    "        )\n",
    "        self.storage_engine.write_data(**self.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b2174-ba84-4112-9033-4841be93505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = PulseParameters(\n",
    "    model_id=\"id1\",\n",
    "    model_version=\"ver1\",\n",
    "    data_id=\"dat1\",\n",
    "    reference_data_storage=reference_data,\n",
    "    target_name=\"target_feature_name\",\n",
    "    storage_engine=\"influxdb\",\n",
    "    timestamp_column_name=\"_time\",\n",
    "    login={\n",
    "        \"url\": \"url_influxdb\",\n",
    "        \"token\": \"mytoken\",\n",
    "        \"org\": \"pulsarml\",\n",
    "        \"bucket_name\": \"demo\",\n",
    "    },\n",
    "    other_labels={\"timezone\": \"EST\", \"reference_dataset\": reference_data},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d26eb-efef-44b3-a53e-93e717ebc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pulsar_data_collection.database_connectors.influxdb import InfluxdbActions\n",
    "# from pulsar_data_collection.config import factories\n",
    "# from pulsar_data_collection.models import DataWithPrediction, PulseParameters\n",
    "# from pulsar_data_collection.pulse import Pulse\n",
    "from datetime import datetime\n",
    "# Convert prediction_numpy to a DataFrame\n",
    "prediction_df = pd.DataFrame(prediction_numpy)\n",
    "\n",
    "# Reset the index of data_points and prediction_df\n",
    "df_test_drifted = df_test_drifted.reset_index(drop=True)\n",
    "prediction_df = prediction_df.reset_index(drop=True)\n",
    "\n",
    "df_test_drifted.columns = df_test_drifted.columns.astype(str)\n",
    "\n",
    "#  Add the timestamp field to param_dict\n",
    "param_dict[\"timestamp\"] = datetime.now()\n",
    "\n",
    "print('param_dictionary:',param_dict)\n",
    "\n",
    "influxdb.write_data(\n",
    "    client=param_dict[\"client\"],\n",
    "    bucket_name=param_dict[\"bucket_name\"],\n",
    "    data_frame_measurement_name=param_dict[\"data_frame_measurement_name\"],\n",
    "    data_frame_timestamp_column=param_dict[\"data_frame_timestamp_column\"],\n",
    "    tags={'model_id': 'mod1', 'model_version': 'ver1', 'data_id': 'data1'},\n",
    "    prediction=prediction_df,\n",
    "    data_points=df_test_drifted,\n",
    "    timestamp=param_dict[\"timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027f4a7-95ef-47fa-b709-a1e9c3db463d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
